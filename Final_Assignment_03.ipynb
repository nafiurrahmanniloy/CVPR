{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40798,"status":"ok","timestamp":1750912423056,"user":{"displayName":"Ridwan Rafid","userId":"09895505424772285072"},"user_tz":-360},"id":"_4zF4S51TruF","outputId":"f7d5f914-92f9-4a71-b043-07cc7c8f2bd7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# STEP 1: Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1yZ3fYfnOYbjcqCDOqfpAG2VnxuRujZKR"},"id":"0e0sry0ZWTMi","outputId":"50d055fa-9b9e-4fd6-8bc7-929eb631303c"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Dropout, BatchNormalization\n","from tensorflow.keras.models import Model\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.image import load_img\n","from PIL import Image\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.metrics import MeanIoU\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# === Paths ===\n","image_dir = '/content/drive/MyDrive/food_dataset/images'\n","mask_dir = '/content/drive/MyDrive/food_dataset/mask'\n","\n","IMG_HEIGHT = 224\n","IMG_WIDTH = 224\n","N_CLASSES = 4\n","\n","# === Color Map ===\n","color_map = {\n","    (0, 0, 0): 0,\n","    (255, 0, 0): 1,\n","    (0, 255, 0): 2,\n","    (0, 0, 255): 3\n","}\n","\n","def rgb_to_label(mask_rgb):\n","    label_mask = np.zeros((mask_rgb.shape[0], mask_rgb.shape[1]), dtype=np.uint8)\n","    for rgb, label in color_map.items():\n","        matches = np.all(mask_rgb == rgb, axis=-1)\n","        label_mask[matches] = label\n","    return label_mask\n","\n","def augment_image(img, mask):\n","    img = tf.convert_to_tensor(img, dtype=tf.float32)\n","    mask = tf.convert_to_tensor(mask, dtype=tf.int32)\n","    if len(img.shape) == 2:\n","        img = tf.expand_dims(img, -1)\n","    if len(mask.shape) == 2:\n","        mask = tf.expand_dims(mask, -1)\n","\n","    if tf.random.uniform(()) > 0.5:\n","        img = tf.image.flip_left_right(img)\n","        mask = tf.image.flip_left_right(mask)\n","    if tf.random.uniform(()) > 0.5:\n","        img = tf.image.flip_up_down(img)\n","        mask = tf.image.flip_up_down(mask)\n","    if tf.random.uniform(()) > 0.5:\n","        img = tf.image.rot90(img)\n","        mask = tf.image.rot90(mask)\n","\n","    img = tf.squeeze(img, axis=-1) if img.shape[-1] == 1 else img\n","    mask = tf.squeeze(mask, axis=-1) if mask.shape[-1] == 1 else mask\n","\n","    return img.numpy(), mask.numpy()\n","\n","def load_data(img_dir, mask_dir, augment=False):\n","    images = []\n","    masks = []\n","\n","    for file in sorted(os.listdir(img_dir)):\n","        if ('_mask' in file) or (not (file.endswith('.jpg') or file.endswith('.png') or file.endswith('.jpeg'))):\n","            continue\n","\n","        filename_base = os.path.splitext(file)[0]\n","        mask_filename = filename_base + '_mask.png'\n","        mask_path = os.path.join(mask_dir, mask_filename)\n","        if not os.path.exists(mask_path):\n","            print(f\"Skipping {file} â€” mask {mask_filename} not found.\")\n","            continue\n","\n","        try:\n","            img = load_img(os.path.join(img_dir, file), target_size=(IMG_HEIGHT, IMG_WIDTH))\n","            img = np.array(img).astype('float32') / 255.0\n","        except Exception as e:\n","            print(f\"Error loading {file}: {e}\")\n","            continue\n","\n","        mask = Image.open(mask_path).resize((IMG_WIDTH, IMG_HEIGHT)).convert(\"RGB\")\n","        mask = np.array(mask)\n","        mask = rgb_to_label(mask)\n","\n","        if augment:\n","            img, mask = augment_image(img, mask)\n","\n","        images.append(img)\n","        masks.append(mask)\n","\n","    images = np.array(images)\n","    masks = tf.keras.utils.to_categorical(np.array(masks), num_classes=N_CLASSES)\n","    return images, masks\n","\n","# === Load + Augment ===\n","images, masks = load_data(image_dir, mask_dir, augment=True)\n","\n","# === Split ===\n","x_train, x_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=42)\n","\n","# === Loss ===\n","def dice_loss(y_true, y_pred):\n","    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n","    denominator = tf.reduce_sum(y_true + y_pred)\n","    return 1 - numerator / (denominator + 1e-6)\n","\n","def combined_loss(y_true, y_pred):\n","    return tf.keras.losses.categorical_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n","\n","# === U-Net with MobileNetV2 encoder ===\n","def build_unet_mobilenetv2(input_shape=(224, 224, 3), num_classes=4, dropout=0.1):\n","    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n","    skips = [\n","        base_model.get_layer(\"block_1_expand_relu\").output,\n","        base_model.get_layer(\"block_3_expand_relu\").output,\n","        base_model.get_layer(\"block_6_expand_relu\").output,\n","        base_model.get_layer(\"block_13_expand_relu\").output,\n","    ]\n","    x = base_model.get_layer(\"block_16_project\").output\n","\n","    for skip in reversed(skips):\n","        x = UpSampling2D()(x)\n","        x = Concatenate()([x, skip])\n","        x = Conv2D(256, 3, padding=\"same\", activation=\"relu\")(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","\n","    x = UpSampling2D()(x)\n","    x = Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n","    x = BatchNormalization()(x)\n","    outputs = Conv2D(num_classes, 1, activation=\"softmax\")(x)\n","\n","    model = Model(inputs=base_model.input, outputs=outputs)\n","    return model\n","\n","# === Compile ===\n","model = build_unet_mobilenetv2()\n","model.compile(optimizer='adam', loss=combined_loss, metrics=['accuracy', MeanIoU(num_classes=4)])\n","model.summary()\n","\n","# === Train ===\n","early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","history = model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=2, epochs=50, callbacks=[early_stop])\n","\n","# === Plot History ===\n","plt.figure(figsize=(10, 5))\n","plt.plot(history.history['loss'], label='Train Loss')\n","plt.plot(history.history['val_loss'], label='Val Loss')\n","plt.legend()\n","plt.title(\"Loss Over Epochs\")\n","plt.show()\n","\n","# === Predictions ===\n","preds = model.predict(x_test)\n","\n","def show_result(idx):\n","    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n","    ax[0].imshow(x_test[idx])\n","    ax[0].set_title(\"Input\")\n","    ax[1].imshow(np.argmax(y_test[idx], axis=-1), cmap='jet')\n","    ax[1].set_title(\"Ground Truth\")\n","    ax[2].imshow(np.argmax(preds[idx], axis=-1), cmap='jet')\n","    ax[2].set_title(\"Prediction\")\n","    for a in ax:\n","        a.axis('off')\n","    plt.tight_layout()\n","    plt.show()\n","\n","for i in range(min(5, len(x_test))):\n","    show_result(i)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyM+WqMoZF7rPJsQPTDc0MVG"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}